---
title: "Step-by-Step Guide to Kafka Cluster Deployment Using Ansible"
seoTitle: "Kafka Cluster Deployment with Ansible Guide"
seoDescription: "Deploy an automated Kafka cluster using Ansible to simplify infrastructure, ensure scalability, and enhance monitoring"
datePublished: Sat Aug 31 2024 14:53:10 GMT+0000 (Coordinated Universal Time)
cuid: cm0i9ip6q000609l331jt5pgl
slug: step-by-step-guide-to-kafka-cluster-deployment-using-ansible
cover: https://cdn.hashnode.com/res/hashnode/image/upload/v1725115963102/ab3b0bbe-cda4-415a-b88d-baa3235bf1cc.png

---

### The Mission: 3 Zookeepers, 3 Kafka Brokers, 100% Automation

Setting up a Kafka cluster used to be a real headache. Imagine trying to organize a big party where none of the guests speak the same language, and you'll get an idea of what it was like before Ansible came along.

I remember the first time I tried to set up a Kafka cluster by hand. It was like trying to solve a giant puzzle where the pieces kept changing shape. Dealing with Zookeeper and getting all the Kafka brokers to work together across different servers was no easy task.

But don't worry! This story isn't just about the problems I faced. It's about how Ansible came to the rescue, like a helpful friend, and made everything much easier. Ansible helped bring order to our messy data system and saved us from the nightmare of setting things up manually.

If you're new to Kafka or need a refresher on its fundamentals, I recommend checking out my previous article: [Apache Kafka for DevOps: From Confusion to Confidence - A Beginner's Tutorial](https://devopswizard.hashnode.dev/step-by-step-guide-to-kafka-cluster-deployment-using-ansible). It covers the basics of Kafka, its publish-subscribe model, and even includes a tutorial on setting up a Kafka cluster with Docker. That article will give you a solid foundation before we dive into the world of Ansible automation for Kafka deployment.

So, whether you've been working with computer systems for years or you're just starting out and feeling a bit lost, stick around. I think you'll find this story useful. You might laugh a bit, you'll probably feel relieved, and I bet you'll see Kafka clusters in a whole new light by the end. Let's embark on this journey of automating Kafka cluster deployment with Ansible!

## The Task: Building a Better Data System

It all started with a simple request from my boss. He said, "We need a Kafka cluster that can handle all our data without breaking. And please make it easy to use. Can you do that?"

Sounds simple, right? Well, not quite. He was asking me to build a strong, expandable messaging system that could handle our growing data needs and be tough enough to survive mistakes from our team. Oh, and I had to make sure we could set it up the same way every time, because doing it by chance and hoping it works isn't a good plan. Who would have guessed?

## Why Ansible? Because I Value My Sanity (and My Weekends)

Look, I've done the whole "SSH into each server and manually configure things" dance before. Never. Again. Ansible lets me define my infrastructure as code, which means:

1. I can version control my entire cluster setup. Rollbacks? No sweat.
    
2. New team member? Here's the repo, now you know our entire setup. Onboarding time cut in half.
    
3. Need to scale up? Just add a few lines to the inventory and rerun the playbook. Done in minutes, not days.
    

Plus, it's agentless. One less thing to install and maintain on my servers? Yes, please!

## The Repo: Where the Magic Happens

Alright, let's dig into the meat of this operation. First, clone the repo:

```bash
git clone https://github.com/thenameisvikash/kafkacluseterplaybook.git
cd kafkacluseterplaybook
git checkout master
```

Here's what you're getting into:

```bash
.
├── group_vars
├── inventory
│   ├── aws.yml
│   ├── onprem_keybased.yml
│   ├── onprem_sudopassword.yml
│   ├── onprem_userpassword.yml
│   └── vagrant.yml
├── roles
├── Vagrantfile
├── ansible.cfg
├── deploy-kafka-cluster.yml
├── destroy-kafka-zookeeper-setup.yml
├── setup-zookeeper.yml
└── vagrant.yml
```

Now, let's break down the key players in this Kafka drama.

## Zookeeper: The Unsung Hero

First up, Zookeeper. It's like the air traffic controller of our Kafka cluster. Here's a snippet from our Zookeeper configuration:

```yaml
---
zookeeper:
  env:
    ZOO_MY_ID: "{{ groups['zookeeper'].index(inventory_hostname) + 1 }}"
    ZOO_SERVERS: "{{ zookeeper_servers }}"
    ZOO_CFG_EXTRA: |
      quorumListenOnAllIPs=true
      clientPort={{ zookeeper_client_port }}
    ZOO_TICK_TIME: "{{ zookeeper_tick_time }}"
    ZOO_INIT_LIMIT: "{{ zookeeper_init_limit }}"
    ZOO_SYNC_LIMIT: "{{ zookeeper_sync_limit }}"
```

Let's break this down:

* `ZOO_MY_ID`: This is crucial. Each Zookeeper instance needs a unique ID. We're using Ansible's magic to automatically assign these based on the inventory order. No more manually setting IDs!
    
* `ZOO_SERVERS`: This is where we define our Zookeeper ensemble. The format is [`server.id`](http://server.id)`=host:port:port`. The first port (2888 in our case) is for follower connections to the leader, and the second (3888) is for leader election.
    
* `quorumListenOnAllIPs=true`: This little gem allows Zookeeper to listen on all IPs for quorum and leader election traffic. Crucial when you're dealing with Docker or complex networking setups.
    
* `ZOO_TICK_TIME`, `ZOO_INIT_LIMIT`, `ZOO_SYNC_LIMIT`: These are timing configurations. TICK\_TIME is the basic time unit in milliseconds, INIT\_LIMIT is the number of ticks allowed for followers to connect and sync with the leader, and SYNC\_LIMIT is the number of ticks allowed for followers to sync with the leader.
    

Why these values? Well, TICK\_TIME at 2000ms (2 seconds) is a good default. The INIT\_LIMIT of 10 means we allow 20 seconds for initial syncing, which is usually plenty. SYNC\_LIMIT at 5 gives us 10 seconds for syncing, which balances between allowing enough time for syncs and detecting failures quickly.

## Kafka: The Main Event

Now, onto Kafka itself. Here's where things get really interesting:

```yaml
---
kafka:
  env:
    KAFKA_BROKER_ID: "{{ groups['kafka'].index(inventory_hostname) + 1 }}"
    KAFKA_ZOOKEEPER_CONNECT: "{{ kafka_zookeeper_connect }}"
    KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://{{ ansible_host }}:{{ kafka_port }}"
    KAFKA_LISTENERS: "PLAINTEXT://0.0.0.0:{{ kafka_port }}"
    KAFKA_LOG_SEGMENT_BYTES: "{{ kafka_log_segment_bytes }}"
    KAFKA_LOG_RETENTION_BYTES: "{{ kafka_log_retention_bytes }}"
    KAFKA_LOG_RETENTION_MS: "{{ kafka_log_retention_ms }}"
    KAFKA_OPTS: "-javaagent:/usr/app/jmx_prometheus_javaagent-0.16.1.jar=9582:/usr/app/prometheus-config.yml"
```

Let's dissect this:

* `KAFKA_BROKER_ID`: Like Zookeeper, each Kafka broker needs a unique ID. Again, we're letting Ansible handle this automatically.
    
* `KAFKA_ZOOKEEPER_CONNECT`: This is how our Kafka brokers find Zookeeper. We're listing all three Zookeeper instances for fault tolerance.
    
* `KAFKA_ADVERTISED_LISTENERS`: This is the address that Kafka advertises to clients. Using `{{ ansible_host }}` means we're using the actual IP of the server, not a Docker internal IP.
    
* `KAFKA_LISTENERS`: This tells Kafka to listen on all network interfaces inside the container.
    
* `KAFKA_LOG_SEGMENT_BYTES`: We're setting this to 1GB (1073741824 bytes). This is the maximum size of a single log file. Why 1GB? It's a balance between not having too many small files (which can hurt performance) and not having files so large they're unwieldy.
    
* `KAFKA_LOG_RETENTION_BYTES` and `KAFKA_LOG_RETENTION_MS`: These control how long Kafka keeps data. We're setting bytes to -1 (unlimited) and MS to 604800000 (1 week). This means we'll keep a week's worth of data regardless of size. Adjust these based on your data volume and retention needs!
    
* `KAFKA_OPTS`: This sets up Prometheus monitoring for Kafka. Because let's face it, a Kafka cluster without monitoring is like driving blindfolded.
    

## Monitoring: Keeping an Eye on the Beast

Speaking of monitoring, let's dive a bit deeper into our Prometheus setup. We're using the JMX Exporter to expose Kafka metrics to Prometheus. Here's a basic Prometheus configuration to get you started:

```yaml
---
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'kafka'
    static_configs:
      - targets: ['kafka1:9582', 'kafka2:9582', 'kafka3:9582']

  - job_name: 'zookeeper'
    static_configs:
      - targets: ['zookeeper1:9582', 'zookeeper2:9582', 'zookeeper3:9582']
```

This configuration tells Prometheus to scrape metrics from our Kafka and Zookeeper instances every 15 seconds. You'll want to set up alerts for things like:

* Under-replicated partitions
    
* Offline partitions
    
* Consumer group lag
    
* Broker CPU and memory usage
    

Remember, a monitored Kafka cluster is a happy Kafka cluster!

## The "Aha!" Moment: Dynamic Heap Size

Here's something I'm particularly proud of:

```yaml
- name: Prompt for Kafka heap size if needed
  pause:
    prompt: "Enter Kafka heap size (e.g., 2G, 4G): "
  register: user_heap_size
  when: configure_heap | lower == 'yes'

- name: Set Kafka heap size
  set_fact:
    kafka_heap_opts: "-Xmx{{ user_heap_size.user_input }} -Xms{{ user_heap_size.user_input }}"
  when: configure_heap | lower == 'yes'
```

This lets us set Kafka's heap size dynamically during deployment. Why? Because every environment is different. A dev laptop doesn't need the same heap as a beefy prod server. This flexibility has saved my bacon more than once.

## Running This Beast

Now, you've got options. Because I'm a firm believer in "test locally, deploy globally," I've included a Vagrant setup. Here's how you use it:

1. Spin up the Vagrant environment:
    
    ```bash
    vagrant up
    ```
    
2. Once everything's up and running, deploy the cluster:
    
    ```bash
    ansible-playbook -i vagrant.yml deploy-kafka-cluster.yml
    ```
    
3. If you want to tear it all down (maybe you broke something, I won't judge):
    
    ```bash
    ansible-playbook -i vagrant.yml destroy-kafka-zookeeper-setup.yml
    ```
    
4. To completely obliterate the Vagrant environment:
    
    ```bash
    vagrant destroy -f
    ```
    

But wait, there's more! If you're feeling brave and want to deploy to actual servers, check out the `inventory` directory. You've got options for AWS, on-prem with key-based auth, and on-prem with password auth (both sudo and user). Choose your fighter and update the inventory file accordingly.

## Security Measures: Locking Down Fort Kafka

Now, let's talk security. Our playbook sets up a basic cluster, but in production, you'll want to add some serious locks and alarms. Here's a quick rundown:

1. **Enable SSL/TLS**: Encrypt all communication between clients and brokers. Update your [`server.properties`](http://server.properties):
    
    ```bash
    listeners=SSL://:9092
    advertised.listeners=SSL://:9092
    ssl.keystore.location=/var/private/ssl/kafka.server.keystore.jks
    ssl.keystore.password=test1234
    ssl.key.password=test1234
    ssl.truststore.location=/var/private/ssl/kafka.server.truststore.jks
    ssl.truststore.password=test1234
    ```
    
2. **Set up SASL**: Implement authentication. Add to [`server.properties`](http://server.properties):
    
    ```bash
    sasl.enabled.mechanisms=PLAIN
    sasl.mechanism.inter.broker.protocol=PLAIN
    security.inter.broker.protocol=SASL_SSL
    ```
    
3. **Configure ACLs**: Control who can do what. Use the [`kafka-acls.sh`](http://kafka-acls.sh) script:
    
    ```bash
    bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:Bob --operation Read --topic test-topic
    ```
    

Remember, security is not a one-time setup. It's an ongoing process. Keep your systems updated, rotate credentials regularly, and always follow the principle of least privilege.

## Lessons Learned (The Hard Way)

1. **Start small, scale up**: Begin with modest LOG\_RETENTION settings. You can always increase them, but decreasing them means potentially losing data.
    
2. **Monitor, monitor, monitor**: Set up those Prometheus alerts. Trust me, you want to know about under-replicated partitions before your users do.
    
3. **Security isn't optional**: As we discussed, add those security measures. Your future self (and your company's legal team) will thank you.
    
4. **Backup Zookeeper**: Seriously. A corrupted Zookeeper ensemble can ruin your whole week. Set up regular backups and test your restore process.
    
5. **Document everything**: Your 3 AM self will thank you when trying to debug an issue in production.
    

## Wrapping Up

There you have it - a production-grade Kafka cluster, deployed with Ansible, explained by someone who's been in the trenches. Is it perfect? Probably not. But it's a solid start, and more importantly, it's automated and reproducible.

Remember, DevOps is a journey, not a destination. Start with this setup, watch it like a hawk, and iterate. Your perfect Kafka cluster is out there, and this playbook is your first step towards it.

Now, if you'll excuse me, I have some logs to check and a strong drink to pour. Happy clustering, and may your topics always be perfectly partitioned!

Got war stories of your own? Improvements to suggest? Found a bug that made you question your life choices? Drop an issue in the repo. After all, misery... I mean, DevOps, loves company!